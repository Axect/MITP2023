{"cells":[{"cell_type":"markdown","metadata":{"id":"7S4-X_TYk4g-"},"source":["# Bayesian amplitude regression"]},{"cell_type":"markdown","metadata":{"id":"UBjSaki2k4hG"},"source":["In the lectures you should've now covered, or at least discussed Bayesian networks.\n","Here we'll put this into practice by building a Bayesian neural network in pytorch to perform a regression task on the LHC amplitude for the production of two photons and a gluon in a gluon-gluon collision."]},{"cell_type":"markdown","metadata":{"id":"GV6WJ587rVFn"},"source":["We want to train a network to predict the amplitude for the process $gg\\rightarrow\\gamma\\gamma g$.  So the amplitude depends on the 4-momentum of 5 particles: 2 incoming gluons, 2 outgoing photons, and one outgoing gluon.  \n","\n","The incoming gluons will have no transverse momentum, but their total momentum along the beam pipe is not necessarily zero.\n","\n","The network we will train is a simple fully connected dense network.  This means that the input and output can only be vectors of real numbers.  We want to input the kinematic information on the particles to the network, and train the network to output the corresponding amplitude."]},{"cell_type":"markdown","metadata":{"id":"6Gnn1YJnk4hI"},"source":["We will start by constructing a Bayesian layer in pytorch, and then building the Bayesian loss function.  We will then construct a Bayesian network from these layers, and use it to perform the same amplitude regression from the previous tutorial.  We will discuss how to analyse the outputs of the Bayesian network, and how this gives us the ability to estimate the error on our analysis.  This last step is crucial to the application of any numerical technique in physics."]},{"cell_type":"markdown","metadata":{"id":"olyD_hjzk4hJ"},"source":["#### Outline / tasks:\n"," - Imports \\& plotting set-up\n"," - Loading the data\n"," - Visualising the data\n","     - visualise some of the kinematics of the process (transverse momentum of photons/gluons, MET)\n","     - histogram the amplitudes\n"," - Preprocessing the data\n","     - neural networks like $\\mathcal{O}(1)$ numbers\n","     - how should we preprocess the data?\n"," - Datasets and dataloaders\n","     - details are in the pytorch docs\n"," - Building a Bayesian layer\n"," - Constructing the Bayesian loss function\n"," - Building the Bayesian neural network\n"," - Optimising the neural network\n"," - Plot the train and validation losses as a function of the epochs\n"," - Study the results\n","\n","     \n","Most practical pytorch skills you need for this work is covered in the basics tutorial at https://pytorch.org/tutorials/beginner/basics/intro.html.\n","\n","Please download the training data `tutorial-2-data.zip` and extract it to the folder `data/tutorial-2-data/`."]},{"cell_type":"markdown","metadata":{"id":"kPHzEByxWIUQ"},"source":["Check out the full series of notebook at: https://github.com/heidelberg-hepml/ml-tutorials"]},{"cell_type":"markdown","metadata":{"id":"1J9uq-pJk4hL"},"source":["If you want to run this tutorial in google colab, you can open a new colab and then upload this file.\n","\n","The data can be downloaded using"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"KFrH60g4nYMd"},"outputs":[],"source":["# !wget -O tutorial-2-data.zip \"https://www.dropbox.com/s/n5e66w91rgmbqz2/dlpp-data.zip?dl=0&file_subpath=%2Fdlpp-data%2Ftutorial-2-data\"\n","# !unzip \"tutorial-2-data.zip\"\n","# !mkdir tutorial-2-data\n","# !mv dlpp-data/tutorial-2-data/* tutorial-2-data/.\n","# !rm -r __MACOSX/\n","# !rm -r dlpp-data/\n","# !ls"]},{"cell_type":"markdown","metadata":{"id":"cBVXl7xOnoHF"},"source":["Make sure you switch to a GPU runtime to fully utilize the colab."]},{"cell_type":"markdown","metadata":{"id":"6uu5VsR3k4hO"},"source":["### Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dWuR0j4xk4hP"},"outputs":[],"source":["import os\n","import sys\n","import random\n","import time\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch import Tensor\n","from torch.nn.parameter import Parameter, UninitializedParameter\n","from torch.nn import functional as F\n","from torch.nn import init\n","from torch.nn import Module"]},{"cell_type":"markdown","metadata":{"id":"15iTnIyQk4hR"},"source":["#### Plotting set-up"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"U7X28Kj9k4hT"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import matplotlib\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from matplotlib.lines import Line2D\n","from matplotlib.font_manager import FontProperties\n","import matplotlib.colors as mcolors\n","import colorsys\n"]},{"cell_type":"markdown","metadata":{"id":"gdT5pHrHk4hU"},"source":["## Loading the data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vEsoBwpfk4hV"},"outputs":[],"source":["trn_dat = np.load(\"tutorial-2-data/trn_dat.npy\")\n","trn_amp = np.load(\"tutorial-2-data/trn_amp.npy\")\n","\n","val_dat = np.load(\"tutorial-2-data/val_dat.npy\")\n","val_amp = np.load(\"tutorial-2-data/val_amp.npy\")\n","\n","tst_dat = np.load(\"tutorial-2-data/tst_dat.npy\")\n","tst_amp = np.load(\"tutorial-2-data/tst_amp.npy\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"eO_Mg7Rfk4hW"},"outputs":[{"name":"stdout","output_type":"stream","text":["train data shape: (30000, 5, 4)\n","train amp  shape: (30000,)\n","test  data shape: (30000, 5, 4)\n","test  amp  shape: (30000,)\n","val   data shape: (30000, 5, 4)\n","val   amp  shape: (30000,)\n"]}],"source":["print(f\"train data shape: {trn_dat.shape}\")\n","print(f\"train amp  shape: {trn_amp.shape}\")\n","print(f\"test  data shape: {tst_dat.shape}\")\n","print(f\"test  amp  shape: {tst_amp.shape}\")\n","print(f\"val   data shape: {val_dat.shape}\")\n","print(f\"val   amp  shape: {val_amp.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"Zt7lHLqLE2Bs"},"source":["## Visualising the data"]},{"cell_type":"markdown","metadata":{"id":"81fbfi_vE2Bs"},"source":["Below we will make some kinematic plots of the events in the training sample.  Note however that these are not the physical distributions we would measure at the LHC!  In our training data each of these events is associated with an amplitude, which tells us the probability that the event will be produced in the gluon-gluon interaction.  So to get the physical distributions these events would need to be 'weighted' by their amplitude.  However, right now we just want to visualise our training dataset to see what preprocessing we should do."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"B9OFV8BhE2Bs"},"outputs":[],"source":["def get_init_pz( ev ):\n","    return ev[0][3] + ev[1][3]\n","\n","def get_mass( fv ):\n","    msq = np.round( fv[0]**2 - fv[1]**2 - fv[2]**2 - fv[3]**2 , 5 )\n","    if msq>0:\n","        return np.sqrt( msq )\n","    elif msq<0:\n","        raise Exception( \"mass squared is less than zero\" )\n","    else:\n","        return 0\n","\n","def get_pt( fv ):\n","    ptsq = np.round( fv[1]**2 + fv[2]**2 , 5 )\n","    if ptsq>0:\n","        return np.sqrt( ptsq )\n","    elif ptsq<0:\n","        raise Exception( \"$p_T$ squared is less than zero\" )\n","    else:\n","        return 0\n","\n","def get_met( ev ):\n","    return np.abs( np.sum( [ fv[1]+fv[2] for fv in ev ] ) )"]},{"cell_type":"markdown","metadata":{"id":"xdBlD2-VE2Bt"},"source":["Plotting the initial $p_z$ of the events in the training sample."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"q534NXisE2Bt"},"outputs":[],"source":["trn_dat_init_pz = []\n","for ev in trn_dat:\n","    trn_dat_init_pz.append( get_init_pz( ev ) )"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"hY04q5GEE2Bt"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 700x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig, axs = plt.subplots( 1, 1, figsize=(7,5) )\n","\n","axs.hist( trn_dat_init_pz, histtype='stepfilled', fill=None )\n","\n","axs.set_xlabel( \"initial $p_z$ (GeV)\")\n","axs.set_ylabel( \"number of events\")\n","\n","fig.tight_layout()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"0FGXheVTE2Bu"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 700x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig, axs = plt.subplots( 1, 1, figsize=(7,5) )\n","\n","bins=np.logspace(-9, -3, 21)\n","axs.hist( trn_amp, histtype='stepfilled', fill=None, bins=bins )\n","\n","axs.set_yscale( 'log' )\n","axs.set_xscale( 'log' )\n","\n","axs.set_xlabel( \"train amplitudes\" )\n","axs.set_ylabel( \"number of events\" )\n","\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"QMtnS_Q8E2Bv"},"source":["Plotting the leading photon $p_T$."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"HQdEEb9UE2Bv"},"outputs":[],"source":["trn_dat_leading_photon_pt = []\n","for ev in trn_dat:\n","    trn_dat_leading_photon_pt.append( get_pt( ev[2] ) )"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"m-sEufrhE2Bw"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 700x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig, axs = plt.subplots( 1, 1, figsize=(7,5) )\n","\n","axs.hist( trn_dat_leading_photon_pt, histtype='stepfilled', fill=None )\n","\n","axs.set_yscale( 'log' )\n","\n","axs.set_xlabel( \"leading photon $p_T$ (GeV)\")\n","axs.set_ylabel( \"number of events\" )\n","\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"sUuKazkXk4hd"},"source":["## Preprocessing the data"]},{"cell_type":"markdown","metadata":{"id":"qTnu7t_gE2B0"},"source":["We will be using a dense network, so the data needs to be in vector format.  We will collapse the data for each event to a single vector of dimension $5\\times4=20$.  The fact that the data is ordered here is important.  To predict the amplitude given the kinematics, the network needs to know which entries correspond to which particles in the process."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"1fgebyhOk4he"},"outputs":[],"source":["def get_pt(fv):\n","    \"\"\" returns p_T of given four vector \"\"\"\n","    ptsq = np.round(fv[:, 1]**2 + fv[:, 2]**2, 5)\n","    return np.sqrt(ptsq)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Q_xwlmsAk4hf"},"outputs":[],"source":["# index 2 is leading photon, not gluon (which is 4)\n","trn_dat_gluon_pt = get_pt(trn_dat[:, 4])\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Ou0_Sw_Nk4hg"},"outputs":[],"source":["nev = trn_dat.shape[0]\n","trn_datf = np.reshape(trn_dat, (nev,-1))\n","val_datf = np.reshape(val_dat, (nev,-1))\n","tst_datf = np.reshape(tst_dat, (nev,-1))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"1BX-eMm9k4hh"},"outputs":[{"data":{"text/plain":["(30000, 20)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["trn_datf.shape"]},{"cell_type":"markdown","metadata":{"id":"-HgMAE_SE2B2"},"source":["There are further preprocessing steps we can take.  For example, the inputs are numerically very large $\\mathcal{O}(100)$ and span a large range.  So we could re-scale the inputs by a constant number, or even take the logarithm of the inputs.\n","\n","For now, we'll just re-scale by a constant number, the average final state gluon $p_T$, assuming that this is a natural scale for the problem.  And we should be careful to preprocess the train, validation, and test data in the exact same way."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"7PeIspDPk4hm"},"outputs":[],"source":["gpt = np.mean(trn_dat_gluon_pt)\n","trn_datf = trn_datf / gpt\n","val_datf = val_datf / gpt\n","tst_datf = tst_datf / gpt"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"aT6D4XyZk4ho"},"outputs":[],"source":["trn_datfp = torch.Tensor(trn_datf)\n","val_datfp = torch.Tensor(val_datf)\n","tst_datfp = torch.Tensor(tst_datf)"]},{"cell_type":"markdown","metadata":{"id":"1I2SHiQ3E2B3"},"source":["We should also preprocess the amplitude data.  As we have seen in the plot above, the amplitudes span about 4 orders of magnitude.  This could be difficult for the network to interpolate.  We can aleviate the problem with preprocessing, taking the logarithm of the amplitudes."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Ma3HCrbOk4ho"},"outputs":[],"source":["trn_ampl = np.log(trn_amp)\n","val_ampl = np.log(val_amp)\n","tst_ampl = np.log(tst_amp)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Gsp9AAzwk4hp"},"outputs":[],"source":["trn_amplp = torch.Tensor(trn_ampl)\n","val_amplp = torch.Tensor(val_ampl)\n","tst_amplp = torch.Tensor(tst_ampl)"]},{"cell_type":"markdown","metadata":{"id":"fsEs6lgFk4hq"},"source":["## Datasets and dataloaders"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"eoCKI0aDk4hr"},"outputs":[],"source":["class amp_dataset(Dataset):\n","\n","    def __init__(self, data, amp):\n","        self.data = data\n","        self.amp = amp\n","\n","    def __len__(self):\n","        return len(self.amp)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.amp[idx]"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"wKLvLls9k4hr"},"outputs":[],"source":["trn_dataset = amp_dataset(trn_datfp, trn_amplp.unsqueeze(-1))\n","val_dataset = amp_dataset(val_datfp, val_amplp.unsqueeze(-1))\n","tst_dataset = amp_dataset(tst_datfp, tst_amplp.unsqueeze(-1))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"fPwl52C1k4hs"},"outputs":[],"source":["trn_dataloader = DataLoader(trn_dataset, batch_size=64, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","tst_dataloader = DataLoader(tst_dataset, batch_size=64, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"RZd3Bu67k4ht"},"source":["## Building a Bayesian layer"]},{"cell_type":"markdown","metadata":{"id":"_gvq4bjXk4hu"},"source":["First let's look at the source code for a **basic linear layer** in pytorch:\n","\n","(https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear)"]},{"cell_type":"markdown","metadata":{"id":"aDJSzzkqk4hu"},"source":["```\n","class Linear(Module):\n","    \n","    __constants__ = ['in_features', 'out_features']\n","    in_features: int\n","    out_features: int\n","    weight: Tensor\n","\n","    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n","                 device=None, dtype=None) -> None:\n","        factory_kwargs = {'device': device, 'dtype': dtype}\n","        super(Linear, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n","        if bias:\n","            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self) -> None:\n","        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","        if self.bias is not None:\n","            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n","            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n","            init.uniform_(self.bias, -bound, bound)\n","\n","    def forward(self, input: Tensor) -> Tensor:\n","        return F.linear(input, self.weight, self.bias)\n","\n","    def extra_repr(self) -> str:\n","        return 'in_features={}, out_features={}, bias={}'.format(\n","            self.in_features, self.out_features, self.bias is not None\n","        )\n","```"]},{"cell_type":"markdown","metadata":{"id":"jlKfJsj1k4hv"},"source":["Objects of this class apply a linear transformation to the incoming data: $y = xA^T + b$.\n","\n","The input arguments are required to initialise the layer, so, in the \\_\\_init()\\_\\_ function.  We have:\n","- in_features: size of each input sample\n","- out_features: size of each output sample\n","- bias: If set to ``False``, the layer will not learn an additive bias.  Default: ``True``\n","\n","The shapes are:\n","- Input: $(*, H_{in})$ where $*$ means any number of dimensions including none and $H_{in} = \\text{in\\_features}$.\n","- Output: $(*, H_{out})$ where all but the last dimension are the same shape as the input and $H_{out} = \\text{out\\_features}$.\n","\n","The layer has attributes:\n","- weight: the learnable weights of the module of shape $(\\text{out\\_features}, \\text{in\\_features})$. The values are initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$, where $k = \\frac{1}{\\text{in\\_features}}$\n","- bias:   the learnable bias of the module of shape $(\\text{out\\_features})$.  If `bias` is ``True``, the values are initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k = \\frac{1}{\\text{in\\_features}}$.\n","\n","Examples::\n","\n","    >>> m = nn.Linear(20, 30)\n","    \n","    >>> input = torch.randn(128, 20)\n","    \n","    >>> output = m(input)\n","    \n","    >>> print(output.size())\n","    \n","    torch.Size([128, 30])"]},{"cell_type":"markdown","metadata":{"id":"ogno-VAcBRKy"},"source":["From the lecture, we know that in a Bayesian network the weights are replaced by Gaussian distributions, and on a forward pass we get the output by sampling from that distribution.\n","\n","So the biases are the same as in the linear layer.  But not each weight is a Gaussian distibution and so needs a mean and a variance.  The bias and the mean and variance of the weight distribution will be learnable.  In practice it's easier to work with the log of the variance as it is more stable when optimising the network.\n","\n","We need to be able to sample from the Gaussian weight distributions, and compute derivatives of the output in order to update the network parameters. To do this we use something called the 're-parameterisation trick'. It involves sampling random noise from a unit normal distribution, and then transforming that number using the mean and variance of the weight distribution in this way:\n","\\begin{equation}\n","w = \\mu + \\sigma\\times r\n","\\end{equation}\n","\n","where $r$ is a random number sampled from a unit normal distribution (Gaussian with mean and variance equal to one), $\\mu$ is the mean of the weight distribution, and $\\sigma$ is the standard deviation. In this way we separate the stochastic part of the function from the parameters defining the distribution. And so if we take any differentiable function of $x$ (e.g. an activation function), we can compute derivatives of that function with respect to the mean and variance of the weight distribution.\n","\n","In the `forward` method we then need to implement this reparameterisation trick for the weights, and then apply the same linear transformation as in the standard linear layer.\n","\n","On each forward pass we need to generate a set of random numbers with the same shape as our means and variances.  Choosing a set of random numbers for the sampling is equivalent to 'sampling' a new neural network from the Bayesian neural network.  And sometimes at the end of the analysis, we will want to keep the same network for testing.  So we don't always want to re-sample the random numbers on each forward pass.  To control this we define a flag called `self.resample`, with default set to ``True``.\n","\n","We also need a `reset_parameters` function to reset the parameters in the network.  This is standard for layers in pytorch.  We use a slightly different function to do this than is used in the pytorch linear layer, as can be seen below.\n","\n","From the lecture, you know that the weight distributions require a prior.  The simplest choice for this prior is just a Gaussian distribution with mean zero and variance of one.  Results are typically not too sensitive to this prior, as long as the values are within reasonable limits.  For example, $\\mathcal{O}(1)$ means and standard deviations.  Going beyond $\\mathcal{O}(1)$ numbers just leads to numerical instabilities in the training.  The Bayesian loss function contains a term coming from the KL divergence between the weight distributions in the network and their priors.  So the layers should have some funcitonality to return these values.  The KL divergence for the layer is:\n","\\begin{equation}\n","\\text{KL} = \\sum_{\\text{weights}} 0.5 \\times (  \\mu^2 + \\sigma^2 - \\log\\sigma^2 - 1 )\n","\\end{equation}\n","\n","So let's build the **simplest Bayesian layer** we can."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"KaPF-EDnk4hx"},"outputs":[],"source":["class VBLinear(Module):\n","    # VB -> Variational Bayes\n","\n","    __constants__ = ['in_features', 'out_features']\n","    in_features: int\n","    out_features: int\n","    weight: Tensor\n","\n","    def __init__(self, in_features, out_features):\n","        super(VBLinear, self).__init__()\n","        self.in_features    = in_features\n","        self.out_features   = out_features\n","        self.resample       = True\n","        self.bias           = Parameter(Tensor(out_features))               # bias\n","        self.mu_w           = Parameter(Tensor(out_features, in_features))  # weight\n","        self.logsig2_w      = Parameter(Tensor(out_features, in_features))  # weight\n","        self.random         = torch.randn_like(self.logsig2_w)\n","        self.reset_parameters()                                             # For initialization\n","\n","    def forward(self, inpt):\n","        if self.resample:\n","            self.random = torch.randn_like(self.logsig2_w)\n","        s2_w = self.logsig2_w.exp()                                         # variance\n","        weight = self.mu_w + s2_w.sqrt() * self.random                      # weight\n","        return nn.functional.linear(inpt, weight, self.bias)                #+ 1e-8\n","\n","    def reset_parameters(self):\n","        stdv = 1. / np.sqrt(self.mu_w.size(1))\n","        self.mu_w.data.normal_(0, stdv)\n","        self.logsig2_w.data.zero_().normal_(-9, 0.001)\n","        self.bias.data.zero_()\n","\n","    def KL(self, loguniform=False):\n","        kl = 0.5 * (self.mu_w.pow(2) + self.logsig2_w.exp() - self.logsig2_w - 1).sum()\n","        return kl"]},{"cell_type":"markdown","metadata":{"id":"O2611iYyk4hy"},"source":["Let's test the layers, define:"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"OC-6EqnNk4hy"},"outputs":[],"source":["tlr0 = VBLinear(10, 5)\n","tlr1 = VBLinear(5, 2)"]},{"cell_type":"markdown","metadata":{"id":"TEwfrf0Qk4hz"},"source":["Now some test data, a batch of 20 vectors with 10 elements each:"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"RVk-oE-Mk4h0"},"outputs":[],"source":["x = torch.rand(20, 10)"]},{"cell_type":"markdown","metadata":{"id":"tdkwCLnPk4h0"},"source":["Now pass the data first through layer0 then through layer1:"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"UF38n5ZXk4h1"},"outputs":[{"data":{"text/plain":["tensor([[-0.2636, -0.2891],\n","        [-0.6330, -0.8364],\n","        [-0.4059, -0.5089],\n","        [-0.2686, -0.2623],\n","        [ 0.0277,  0.0804],\n","        [-0.0947, -0.1361],\n","        [-0.4970, -0.5376],\n","        [-0.2599, -0.2803],\n","        [-0.4432, -0.6325],\n","        [-0.6351, -0.7599],\n","        [-0.4640, -0.5033],\n","        [-0.5126, -0.7074],\n","        [-0.2104, -0.2349],\n","        [-0.0721, -0.1626],\n","        [-0.4958, -0.7183],\n","        [-0.4255, -0.4408],\n","        [-0.3210, -0.4068],\n","        [-0.3885, -0.2882],\n","        [-0.4799, -0.5953],\n","        [-0.3538, -0.2758]], grad_fn=<AddmmBackward0>)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["tlr1(tlr0(x))"]},{"cell_type":"markdown","metadata":{"id":"x6ZuuyG5k4h2"},"source":["Note this has the correct shape:"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"eQQNBPJ_k4h2"},"outputs":[{"data":{"text/plain":["torch.Size([20, 2])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["tlr1(tlr0(x)).shape"]},{"cell_type":"markdown","metadata":{"id":"vXcyfd3Uk4h3"},"source":["Also try running the same data through the layer multiple times, you get different results.  This is because of the sampling in the Bayesian layer."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"kIy9SDl9k4h3"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(-0.4882, grad_fn=<SelectBackward0>)\n","tensor(-0.5148, grad_fn=<SelectBackward0>)\n","tensor(-0.5355, grad_fn=<SelectBackward0>)\n","tensor(-0.5324, grad_fn=<SelectBackward0>)\n","tensor(-0.5380, grad_fn=<SelectBackward0>)\n"]}],"source":["for i in range(5):\n","    print(tlr0(x)[0][0])"]},{"cell_type":"markdown","metadata":{"id":"URkyV79Pk4h5"},"source":["## The Bayesian loss function"]},{"cell_type":"markdown","metadata":{"id":"JexlT6qtk4h6"},"source":["From the lectures we know that there are two parts to the Bayesian loss function:\n","- The negative log Gaussian\n","- the KL from the network weights\n","\n","The second comes from the layers, and the first is defined below.  This negative log Gaussian term acts on the two outputs from the Bayesian neural network:\n","- the mean\n","- the variance (which we parameterise as the log variance)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"aSuUV6i1k4h7"},"outputs":[],"source":["def neg_log_gauss(outputs, targets):\n","\n","    #'separate the outputs between means and logsigmas squared'\n","    mu = outputs[:,0]\n","    logsigma2 = outputs[:,1]\n","\n","    out = torch.pow(mu - targets, 2) / (2 * logsigma2.exp()) + 1./2. * logsigma2.exp()\n","\n","    return torch.mean(out)"]},{"cell_type":"markdown","metadata":{"id":"pIxAJ2W9k4iB"},"source":["## Building the Bayesian neural network"]},{"cell_type":"markdown","metadata":{"id":"8Fa1G-mXk4iC"},"source":["We'll build a simple network with one input and one output layer, and two hidden layers.  We define the dimensions of these layers below."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"1r_2vxRGk4iD"},"outputs":[],"source":["ipt_dim = 20\n","opt_dim = 1\n","hdn_dim = 50"]},{"cell_type":"markdown","metadata":{"id":"TnOcHgvEk4iF"},"source":["Now we build a very simple class for our neural network, which we call amp_net."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"tGXH78Nzk4iG"},"outputs":[],"source":["class bayes_amp_net(Module):\n","\n","    # default hdn_dim is 30, but can be changed upon initialisation\n","    def __init__(self, training_size, hdn_dim=50):\n","\n","        super(bayes_amp_net, self).__init__()\n","\n","        # the loss function depends on the amount of training data we have, so we need to store this\n","        self.training_size = training_size\n","\n","        # the activation layers of the network are not bayesian\n","        # and we need to be able to access the bayesian layers separately\n","\n","        self.vb_layers = []\n","        self.all_layers = []\n","\n","        # define the input layer: A VBLinear followed by a ReLU\n","        # remember to store the layers in the lists!\n","        vb_layer = VBLinear(ipt_dim, hdn_dim)\n","        self.vb_layers.append(vb_layer)\n","        self.all_layers.append(vb_layer)\n","\n","        # loop over hidden layers (2 times)\n","        for i in range(2):\n","            # define the hidden layer. use hdn_dim as input and output dimension\n","            vb_layer = VBLinear(hdn_dim, hdn_dim)\n","            self.vb_layers.append(vb_layer)\n","            self.all_layers.append(vb_layer)\n","\n","        # define the output layer. use 2 dimensions to learn the uncertainty sigma_stoch=sigma_model,\n","        # see eq. 1.57 of 2211.01421\n","        vb_layer = VBLinear(hdn_dim, 2)\n","        self.vb_layers.append(vb_layer)\n","        self.all_layers.append(vb_layer)\n","\n","        # define the model as a Sequential net over all layers\n","        self.model = nn.Sequential(*self.all_layers)\n","\n","    # and of course the forward function\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    # we need the KL from the bayesian layers to compute the loss function\n","    def KL(self):\n","        kl = 0\n","        for vb_layer in self.vb_layers:\n","            kl += vb_layer.KL()\n","        return kl / self.training_size\n","\n","    # let's put the neg_log_gauss in the network class as well since it is key to bayesian networks\n","    def neg_log_gauss(outputs, targets):\n","\n","        # 'separate the outputs between means and logsigmas'\n","        mu = outputs[:, 0]\n","        logsigma2 = outputs[:, 1]\n","        out = torch.pow(mu - targets, 2) / (2 * logsigma2.exp()) + 1./2. * logsigma2.exp()\n","        return torch.mean(out)"]},{"cell_type":"markdown","metadata":{"id":"Dn7B1pfQk4iH"},"source":["Check if we have a GPU."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Oq_Vkanyk4iJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"_xonu5S2k4iK"},"source":["Initialise the neural network and send to the GPU if we have one.  We can also print the model to see what layers it has."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ZYWui0urk4iL"},"outputs":[{"name":"stdout","output_type":"stream","text":["bayes_amp_net(\n","  (model): Sequential(\n","    (0): VBLinear()\n","    (1): VBLinear()\n","    (2): VBLinear()\n","    (3): VBLinear()\n","  )\n",")\n"]}],"source":["trn_len = trn_amplp.shape[0]\n","hdn_dim = 50\n","model = bayes_amp_net(trn_len, hdn_dim=hdn_dim).to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"kCdc5XuHk4iO"},"source":["Now we can test it briefly by throwing some random numbers into it."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Nu0rfChTk4iO"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.2842, -0.5402],\n","        [-0.0161, -0.5874],\n","        [-1.1571, -0.5810],\n","        [ 0.5682,  0.0283],\n","        [ 0.4566, -0.1091],\n","        [-0.2232, -0.1155],\n","        [ 0.3374, -0.3214],\n","        [-0.0130, -0.4010]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]}],"source":["# Test the model with a random input\n","batch_size = 8\n","x = torch.rand(batch_size, ipt_dim).to(device)\n","print(model(x))"]},{"cell_type":"markdown","metadata":{"id":"NsQ5XA0Dk4iP"},"source":["Passing the numbers through the Bayesian network gives us different outputs each time we run it:"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"O56RlsRok4iQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.2687, -0.5707],\n","        [ 0.0737, -0.6596],\n","        [-0.9846, -0.5257],\n","        [ 0.5444, -0.0643],\n","        [ 0.4936, -0.1510],\n","        [-0.2010, -0.0332],\n","        [ 0.3587, -0.4283],\n","        [-0.0441, -0.4707]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]}],"source":["# Test the model with a random input\n","print(model(x))"]},{"cell_type":"markdown","metadata":{"id":"Gn_CPp1lk4iR"},"source":["Note again that the output has the correct shape:"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"wiVdzH0Mk4iS"},"outputs":[{"data":{"text/plain":["torch.Size([8, 2])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["model(x).shape"]},{"cell_type":"markdown","metadata":{"id":"NHH6fSTlk4iT"},"source":["The predicitons of the full Bayesian network should vary with each forward pass because of the weight sampling"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"jtcjlwzGk4iX"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([-0.0985, -0.4630], device='cuda:0', grad_fn=<SelectBackward0>)\n","tensor([-0.5106, -0.5363], device='cuda:0', grad_fn=<SelectBackward0>)\n","tensor([-0.1774, -0.3542], device='cuda:0', grad_fn=<SelectBackward0>)\n","tensor([-0.0953, -0.4965], device='cuda:0', grad_fn=<SelectBackward0>)\n","tensor([-0.1554, -0.6236], device='cuda:0', grad_fn=<SelectBackward0>)\n"]}],"source":["# print predictions for the same input data\n","for i in range(5):\n","    print(model(x)[0])"]},{"cell_type":"markdown","metadata":{"id":"yDaOlWYvk4iY"},"source":["## Optimising (training) the neural network"]},{"cell_type":"markdown","metadata":{"id":"3HGQ4uRZk4iZ"},"source":["The Bayesian loss function has two terms which we have already definedl; the negative los Gaussian, and the KL divergence between the network and the network prior.  The latter comes from the KL divergence over the weights in the network."]},{"cell_type":"markdown","metadata":{"id":"Tztwep9qk4ia"},"source":["Now we can write a training loop for a single epoch."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"mauiw9TQk4ia"},"outputs":[],"source":["def train_epoch(dataloader, model, optimizer):\n","\n","    size = len(dataloader.dataset)\n","    model.train()\n","    loss_tot, kl_tot, neg_log_tot = 0.0, 0.0, 0.0\n","    loss_during_opt, kl_during_opt, neg_log_during_opt = 0., 0., 0.\n","\n","    for batch, (X, y) in enumerate(dataloader):\n","\n","        # pass data through network\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","\n","        # compute loss\n","        nl = model.neg_log_gauss(pred, y.squeeze())\n","        kl = model.KL()\n","        loss = nl + kl\n","\n","        loss_during_opt += loss.item()\n","        kl_during_opt += kl.item()\n","        neg_log_during_opt += nl.item()\n","\n","        # reset gradients in optimizer\n","        optimizer.zero_grad()\n","\n","        # compute gradients\n","        loss.backward()\n","\n","        # update weights with optimizer\n","        optimizer.step()\n","\n","        # print the training loss every 100 updates\n","        if batch % 100 == 0:\n","            current = batch * len( X )\n","            print(f\"current batch loss: {loss:>8f} KL: {kl:>8f} Neg-log {nl:>8f}  [{current:>5d}/{size:>5d}]\")\n","    loss_live = loss_during_opt/len(dataloader)\n","    kl_live = kl_during_opt / len(dataloader)\n","    nl_live = neg_log_during_opt / len(dataloader)\n","\n","    print(f\"avg train loss per batch in training: {loss_live:>8f}\")\n","    return loss_live, kl_live, nl_live"]},{"cell_type":"markdown","metadata":{"id":"jedz0a--k4ib"},"source":["To monitor the performance of the network on the regression task we want to calculate the loss of both the training data and the validation data on the same network, so we have the following functions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psVdK6Dek4ic"},"outputs":[],"source":["def val_pass(dataloader, model):\n","\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    nls = 0.0   #neg-log loss\n","    kls = 0.0   #KL loss\n","    vls = 0.0   #total val loss\n","    mse = 0.0\n","\n","    # we don't need gradients here since we only use the forward pass\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            nl = model.neg_log_gauss(pred, y.squeeze())\n","            kl = model.KL()\n","            vl = nl + kl\n","            \n","            mse += torch.mean((pred[:, 0] - y.reshape(-1))**2)\n","            nls += nl\n","            kls += kl\n","            vls += vl\n","\n","    nls /= num_batches\n","    kls /= num_batches\n","    vls /= num_batches\n","    mse /= num_batches\n","    print( f\"avg val loss per batch: {vls:>8f} KL: {kls:>8f} Neg-log {nls:>8f} MSE {mse:>8}\" )\n","\n","    return nls.cpu().numpy(), kls.cpu().numpy(), vls, mse.cpu().numpy()\n","\n","def trn_pass(dataloader, model):\n","\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    nls = 0.0   #neg-log loss\n","    kls = 0.0   #KL loss\n","    vls = 0.0   #total val loss\n","    mse = 0.0\n","\n","    # we don't need gradients here since we only use the forward pass\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            ...\n","\n","\n","\n","            mse += torch.mean((pred[:, 0] - y.reshape(-1))**2)\n","            nls += nl\n","            kls += kl\n","            tls += tl\n","\n","    nls /= num_batches\n","    kls /= num_batches\n","    tls /= num_batches\n","    mse /= num_batches\n","    print( f\"avg trn loss per batch: {tls:>8f} KL: {kls:>8f} Neg-log {nls:>8f} MSE {mse:>8}\" )\n","\n","    return nls.cpu().numpy(), kls.cpu().numpy(), tls, mse.cpu().numpy()"]},{"cell_type":"markdown","metadata":{"id":"ZF-N4BL3k4id"},"source":["Now we can train the model!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rM4uEcWfk4ie","scrolled":true,"tags":[]},"outputs":[],"source":["# a useful function to present things clearer\n","def seperator():\n","    print( \"-----------------------------------------------\" )\n","\n","# reset some parameters\n","batch_size = 128\n","\n","trn_dataset = amp_dataset(trn_datfp.to(device), trn_amplp.unsqueeze(-1).to(device))\n","val_dataset = amp_dataset(val_datfp.to(device), val_amplp.unsqueeze(-1).to(device))\n","tst_dataset = amp_dataset(tst_datfp.to(device), tst_amplp.unsqueeze(-1).to(device))\n","\n","trn_dataloader = DataLoader(trn_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","tst_dataloader = DataLoader(tst_dataset, batch_size=batch_size, shuffle=True)\n","epochs = 500\n","\n","# re-initialise the model and the optimizer\n","hdn_dim = 50\n","trn_len = trn_amplp.shape[0]\n","print(f\"Training dataset length: {trn_len}\")\n","model = bayes_amp_net(trn_len, hdn_dim=hdn_dim).to(device)\n","learning_rate = 5e-4\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","seperator()\n","print(\"model architecture\")\n","seperator()\n","print(model)\n","total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Model has {total_parameters:d} trainable parameters\")\n","\n","\n","# track train and val losses\n","trn_nl_losses = []\n","trn_kl_losses = []\n","trn_losses = []\n","trn_mse_losses = []\n","val_nl_losses = []\n","val_kl_losses = []\n","val_losses = []\n","val_mse_losses = []\n","trn_nl_losses_live = []\n","trn_kl_losses_live = []\n","trn_losses_live = []\n","\n","for t in range(epochs):\n","    seperator()\n","    print(f\"Epoch {t+1}\")\n","    seperator()\n","    loss_live, kl_live, nl_live = train_epoch(trn_dataloader, model, optimizer)\n","    trn_nl_losses_live.append(nl_live)\n","    trn_kl_losses_live.append(kl_live)\n","    trn_losses_live.append(loss_live)\n","    seperator()\n","    trn_nl_loss, trn_kl_loss, trn_loss, trn_mse_loss = trn_pass(trn_dataloader, model)\n","    trn_nl_losses.append(trn_nl_loss)\n","    trn_kl_losses.append(trn_kl_loss)\n","    trn_losses.append(trn_loss)\n","    trn_mse_losses.append(trn_mse_loss)\n","    seperator()\n","    val_nl_loss, val_kl_loss, val_loss, val_mse_loss = val_pass(val_dataloader, model)\n","    val_nl_losses.append(val_nl_loss)\n","    val_kl_losses.append(val_kl_loss)\n","    val_losses.append(val_loss)\n","    val_mse_losses.append(val_mse_loss)\n","    seperator()\n","    print( \"|\" )\n","\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"aX_EYEu2k4if"},"source":["## Plot the train and validation losses as a function of the epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyJfasl8k4if"},"outputs":[],"source":["fig, axs = plt.subplots(1, 4, figsize=(18,5))\n","\n","c1 = 'tab:red'\n","c2 = 'tab:green'\n","\n","axs[0].plot(trn_losses, label=\"train\", color=c1)\n","axs[0].plot(val_losses, label=\"val\", color=c2)\n","axs[0].plot(trn_losses_live, label=\"train live\", color=c1, ls='dashed')\n","axs[0].set_xlabel(\"epoch\")\n","axs[0].set_ylabel(\"Total loss\")\n","axs[0].set_ylim(-2, 5)\n","axs[0].legend()\n","\n","axs[1].plot(trn_nl_losses, label=\"train\", color=c1)\n","axs[1].plot(val_nl_losses, label=\"val\", color=c2)\n","axs[1].plot(trn_nl_losses_live, label=\"train live\", color=c1, ls='dashed')\n","axs[1].set_xlabel(\"epoch\")\n","axs[1].set_ylabel(\"Neg-log-gauss loss\")\n","axs[1].set_ylim(-2, 5)\n","axs[1].legend()\n","\n","axs[2].plot(trn_kl_losses, label=\"train\", color=c1)\n","axs[2].plot(val_kl_losses, label=\"val\", color=c2)\n","axs[2].plot(trn_kl_losses_live, label=\"train live\", color=c1, ls='dashed')\n","axs[2].set_yscale('log')\n","axs[2].set_xlabel(\"epoch\")\n","axs[2].set_ylabel(\"KL loss\")\n","axs[2].legend()\n","\n","\n","axs[3].plot(trn_mse_losses, label=\"train\", color=c1)\n","axs[3].plot(val_mse_losses, label=\"val\", color=c2)\n","axs[3].set_yscale('log')\n","axs[3].set_xlabel(\"epoch\")\n","axs[3].set_ylabel(\"MSE Loss\")\n","axs[3].legend()\n","\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"vFV-TKWqk4ii"},"source":["We can see that both the train and validation losses are being reduced during training, the model is fitting well!"]},{"cell_type":"markdown","metadata":{"id":"_FxstvzRk4ij"},"source":["## Study the results"]},{"cell_type":"markdown","metadata":{"id":"I8OczHv2k4ij"},"source":["Now we want to get some visualisation of how well our amplitude regression has worked.\n","\n","The simplest thing we can do is to pass our data through the neural network to get a predicted amplitude for each event, then histogram this and compare it to the histogram of the true amplitudes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59usBKvak4ik"},"outputs":[],"source":["def get_prediction(model, dataloader, n_monte=30):\n","\n","    # we don't need gradients here since we only use the forward pass\n","    with torch.no_grad():\n","\n","        # sample from weight distributions\n","        amps_samples = []\n","        sigma2_samples = []\n","        for i in range(n_monte):\n","            print(f\"Evaluating prediction: {i+1} / {n_monte}\")\n","            # go through dataset\n","            amps = []\n","            sigma2 = []\n","            for X, y in dataloader:\n","                pred = model(X).detach().cpu().numpy()\n","                amps.extend(pred[:, 0]) # dimensions: [batch_size, 2]\n","                sigma2.extend(np.exp(pred[:, 1]))\n","\n","            amps_samples.append(amps)\n","            sigma2_samples.append(sigma2)\n","\n","    # dimensionaility (n_monte, batch_size)\n","    amps_samples = np.stack(amps_samples, axis=0)\n","    sigma2_samples = np.stack(sigma2_samples, axis=0)\n","\n","    return amps_samples, sigma2_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hw7yMZ-0k4il"},"outputs":[],"source":["# TURN OFF shuffeling to not mess up the weight sampling!\n","trn_dataloader = DataLoader(trn_dataset, batch_size=64, shuffle=False)\n","val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","tst_dataloader = DataLoader(tst_dataset, batch_size=64, shuffle=False)\n","\n","# dimensionality is (n_monte, batch_size)\n","pred_trn_ampls_samples, sigma2_trn_samples = get_prediction(model, trn_dataloader)\n","pred_val_ampls_samples, sigma2_val_samples = get_prediction(model, val_dataloader)\n","\n","# compute mean prediction, standard deviation of predictions and mean sigma-output, see lecture notes\n","pred_trn_ampls = np.mean(pred_trn_ampls_samples, axis=0) # mean prediction\n","pred_trn_ampls_std = np.std(pred_trn_ampls_samples, axis=0)\n","pred_trn_ampls_std_stoch = np.sqrt(np.mean(sigma2_trn_samples, axis=0))\n","pred_trn_ampls_std_tot = np.sqrt(pred_trn_ampls_std**2 + pred_trn_ampls_std_stoch**2)\n","\n","# same for validation data\n","pred_val_ampls = np.mean(pred_val_ampls_samples, axis=0) # mean prediction\n","pred_val_ampls_std = np.std(pred_val_ampls_samples, axis=0)\n","pred_val_ampls_std_stoch = np.sqrt(np.mean(sigma2_val_samples, axis=0))\n","pred_val_ampls_std_tot = np.sqrt(pred_val_ampls_std**2 + pred_val_ampls_std_stoch**2)\n","\n","print(\"Mean std pred: \", np.mean(pred_trn_ampls_std))\n","print(\"Mean std stoch: \", np.mean(pred_trn_ampls_std_stoch))\n"]},{"cell_type":"markdown","metadata":{"id":"vyEh2-phk4im"},"source":["First for the training data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcUy4m6Lk4in"},"outputs":[],"source":["fig, axs = plt.subplots(1, 4, figsize=(18,5))\n","\n","c1 = 'tab:red'\n","c2 = 'tab:green'\n","\n","(n1, bins, patches1 ) = axs[0].hist(trn_ampl, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","(n2, _, patches2 ) = axs[0].hist(pred_trn_ampls, histtype='stepfilled', fill=None, edgecolor=c2, label=\"train preds\", bins=bins)\n","\n","bins= np.linspace(0, 1., 50)\n","(n3, _, patches3 ) = axs[1].hist(pred_trn_ampls_std, bins=bins, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","(n4, _, patches4 ) = axs[2].hist(pred_trn_ampls_std_tot, bins=bins, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","(n5, _, patches5 ) = axs[3].hist(pred_trn_ampls_std_stoch, bins=bins, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","\n","axs[0].set_yscale('log')\n","axs[0].set_xlabel(\"log(train amplitudes)\")\n","axs[0].set_ylabel(\"number of events\")\n","axs[0].legend(loc='best')\n","\n","axs[1].set_xlabel(\"Predictive Uncertainty\")\n","axs[1].set_ylabel(\"number of events\")\n","axs[1].legend(loc='best')\n","\n","axs[2].set_xlabel(\"Total Uncertainty \")\n","axs[2].set_ylabel(\"number of events\")\n","axs[2].legend(loc='best')\n","\n","axs[3].set_xlabel(\"Stochastic Uncertainty\")\n","axs[3].set_ylabel(\"number of events\")\n","axs[3].legend(loc='best')\n","\n","fig.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ8L9rFdk4io"},"outputs":[],"source":["fig, axs = plt.subplots(1, 4, figsize=(20,5))\n","\n","c1 = 'tab:red'\n","c2 = 'tab:green'\n","\n","n_bins = 50\n","bins = np.linspace(-5, 5, n_bins)\n","\n","pull = (trn_ampl - pred_trn_ampls) / trn_ampl\n","pull_normalized_tot = (trn_ampl - pred_trn_ampls) / pred_val_ampls_std_tot\n","pull_normalized_stoch = (trn_ampl - pred_trn_ampls) / pred_val_ampls_std_stoch\n","pull_normalized = (trn_ampl - pred_trn_ampls) / pred_val_ampls_std\n","\n","\n","(n1, bins1, patches1 ) = axs[0].hist( pull, histtype='stepfilled', bins=n_bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n","(n2, bins2, patches2 ) = axs[1].hist( pull_normalized_tot, histtype='stepfilled', bins=np.linspace(-5, 5, n_bins), fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n","(n3, bins3, patches3 ) = axs[2].hist( pull_normalized_stoch, histtype='stepfilled', bins=np.linspace(-5, 5, n_bins), fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n","(n4, bins4, patches4 ) = axs[3].hist( pull_normalized, histtype='stepfilled', bins=n_bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n","\n","axs[0].set_xlabel(\"Pull\")\n","axs[0].set_ylabel(\"number of events\")\n","axs[0].legend(loc='best')\n","\n","axs[1].set_xlabel(\"Pull total unc\")\n","axs[1].set_ylabel(\"number of events\")\n","axs[1].legend(loc='best')\n","\n","axs[2].set_xlabel(\"Pull stochastic unc\")\n","axs[2].set_ylabel(\"number of events\")\n","axs[2].legend(loc='best')\n","\n","axs[3].set_yscale('log')\n","axs[3].set_xlabel(\"Pull predictive unc\")\n","\n","fig.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"omHItyIPk4ip"},"outputs":[],"source":["# same plots for exp(log (train amplitudes) ) = train amplitudes\n","\n","fig, axs = plt.subplots(1, 4, figsize=(20,5))\n","\n","c1 = 'tab:red'\n","c2 = 'tab:green'\n","\n","n_bins = 50\n","bins =np.linspace(-5, 5, n_bins)\n","\n","# revert preprocessing\n","trn_ampl_exp = np.exp(trn_ampl)\n","pred_trn_ampls_exp = np.exp(pred_trn_ampls)\n","pred_val_ampls_std_tot_exp = np.exp(trn_ampl) * pred_val_ampls_std_tot # error propagation\n","pred_val_ampls_std_stoch_exp = np.exp(trn_ampl) * pred_val_ampls_std_stoch # error propagation\n","pred_val_ampls_std_exp = np.exp(trn_ampl) * pred_val_ampls_std # error propagation\n","\n","pull = (trn_ampl_exp - pred_trn_ampls_exp) / trn_ampl_exp\n","pull_normalized_tot = (trn_ampl_exp - pred_trn_ampls_exp) / pred_val_ampls_std_tot_exp\n","pull_normalized_stoch = (trn_ampl_exp - pred_trn_ampls_exp) / pred_val_ampls_std_stoch_exp\n","pull_normalized = (trn_ampl_exp - pred_trn_ampls_exp) / pred_val_ampls_std_exp\n","(n1, bins1, patches1 ) = axs[0].hist(pull, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","(n2, bins2, patches2 ) = axs[1].hist(pull_normalized_tot, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","(n3, bins3, patches3 ) = axs[2].hist(pull_normalized_stoch, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","(n4, bins4, patches4 ) = axs[3].hist(pull_normalized, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\")\n","\n","\n","axs[0].set_xlabel(\"Pull\")\n","axs[0].set_ylabel(\"number of events\")\n","axs[0].set_xlim([-5, 5])\n","axs[0].legend(loc='best')\n","\n","axs[1].set_xlabel(\"Pull total unc\")\n","axs[1].set_ylabel(\"number of events\")\n","axs[1].legend(loc='best')\n","\n","axs[2].set_xlabel(\"Pull stochastic unc\")\n","axs[2].set_ylabel(\"number of events\")\n","axs[2].legend(loc='best')\n","\n","axs[3].set_yscale('log')\n","axs[3].set_xlabel(\"Pull predictive unc\")\n","axs[3].set_ylabel(\"number of events\")\n","axs[3].legend(loc='best')\n","\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"i5HwINqMk4is"},"source":["The error is lowest in the regions where there is more training data, this is expected.  The more data the network has to learn from, the better it can learn to predict the correct amplitude."]},{"cell_type":"markdown","metadata":{"id":"lyVmFQVAk4is"},"source":["And then for the validation data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgWbyEhbk4it"},"outputs":[],"source":["fig, axs = plt.subplots(1, 1, figsize=(7, 5))\n","\n","c1 = 'tab:red'\n","c2 = 'tab:green'\n","\n","(n1, bins, patches1) = axs.hist(val_ampl, histtype='stepfilled', fill=None, edgecolor=c1, label=\"val data\", ls=\"--\")\n","(n2, _, patches2) = axs.hist(pred_val_ampls, histtype='stepfilled', fill=None, edgecolor=c2, label=\"val preds\", bins=bins)\n","\n","axs.set_yscale('log')\n","\n","axs.set_xlabel(\"log( train amplitudes )\")\n","axs.set_ylabel(\"number of events\")\n","\n","axs.legend(loc='best')\n","\n","fig.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlbJookdk4iu"},"outputs":[],"source":["fig, axs = plt.subplots(1, 1, figsize=(7,5))\n","\n","c1 = 'tab:red'\n","c2 = 'tab:green'\n","\n","axs.plot((bins[1:]+bins[:-1])/2., np.abs((n1-n2)/n1), color=c1)\n","\n","axs.set_xlabel(\"log(train amplitudes)\")\n","axs.set_ylabel(\"Error\")\n","\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"dpYEovJwVO3O"},"source":["Extra:\n","Code a more general VBLayer where with modifiable Gaussian prior $\\mathcal{N}(\\mu_p, \\sigma_p^2)$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUDwjvEfk4iu"},"outputs":[],"source":["class VBLinear(Module):\n","    # VB -> Variational Bayes\n","\n","..."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1kxVsd0Vn4prFJ4_5t2XB5uhQDykNiv1-","timestamp":1689755818021},{"file_id":"1-4hFUAsPc5_F2xPE5Cs1pqCT83Yaw-Ti","timestamp":1681245893008}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
